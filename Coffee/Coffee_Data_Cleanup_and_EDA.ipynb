{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02532c5-27b1-4de9-b264-b36b320cc0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RONDA --START -- IMPORT CODE AND DATA CLEANUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "887f66ae-9b37-4cfb-8a00-0247a54e1a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model as lm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e363575-29da-4501-976c-2ea69ea10263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ethiopia', 'Guatemala', 'Brazil', 'Peru', 'United States',\n",
       "       'United States (Hawaii)', 'Indonesia', 'China', 'Costa Rica',\n",
       "       'Mexico', 'Uganda', 'Honduras', 'Taiwan', 'Nicaragua',\n",
       "       'Tanzania, United Republic Of', 'Kenya', 'Thailand', 'Colombia',\n",
       "       'Panama', 'Papua New Guinea', 'El Salvador', 'Japan', 'Ecuador',\n",
       "       'United States (Puerto Rico)', 'Haiti', 'Burundi', 'Vietnam',\n",
       "       'Philippines', 'Rwanda', 'Malawi', 'Laos', 'Zambia', 'Myanmar',\n",
       "       'Mauritius', 'Cote d?Ivoire', nan, 'India'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a path to the csv and read it into a Pandas DataFrame\n",
    "csv_path = Path('data/merged_data_cleaned.csv')\n",
    "coffee_df = pd.read_csv(csv_path, encoding=\"utf8\")\n",
    "coffee_df[\"Country.of.Origin\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4043bcb4-a071-42d6-8916-37bf8bc86368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Species', 'Owner', 'Country.of.Origin', 'Farm.Name',\n",
       "       'Lot.Number', 'Mill', 'ICO.Number', 'Company', 'Altitude', 'Region',\n",
       "       'Producer', 'Number.of.Bags', 'Bag.Weight', 'In.Country.Partner',\n",
       "       'Harvest.Year', 'Grading.Date', 'Owner.1', 'Variety',\n",
       "       'Processing.Method', 'Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body',\n",
       "       'Balance', 'Uniformity', 'Clean.Cup', 'Sweetness', 'Cupper.Points',\n",
       "       'Total.Cup.Points', 'Moisture', 'Category.One.Defects', 'Quakers',\n",
       "       'Color', 'Category.Two.Defects', 'Expiration', 'Certification.Body',\n",
       "       'Certification.Address', 'Certification.Contact', 'unit_of_measurement',\n",
       "       'altitude_low_meters', 'altitude_high_meters', 'altitude_mean_meters'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d5d41c62-8255-4d38-8e5c-07c9689033ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_df_new = coffee_df.rename(columns={'Total.Cup.Points': 'CoffeeScore',\n",
    "                                            'Country.of.Origin': 'Country_of_Origin',\n",
    "                                         'Processing.Method': 'Processing_Method'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019c1f3-0370-46f7-bbf3-1577eb5e75c1",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "(RONDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6d1da5af-8f5c-4aec-a7fe-719b9ebb91c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Species</th>\n",
       "      <th>Owner</th>\n",
       "      <th>Country_of_Origin</th>\n",
       "      <th>Farm.Name</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Region</th>\n",
       "      <th>Number.of.Bags</th>\n",
       "      <th>Bag.Weight</th>\n",
       "      <th>Harvest.Year</th>\n",
       "      <th>...</th>\n",
       "      <th>CoffeeScore</th>\n",
       "      <th>Moisture</th>\n",
       "      <th>Category.One.Defects</th>\n",
       "      <th>Quakers</th>\n",
       "      <th>Color</th>\n",
       "      <th>Category.Two.Defects</th>\n",
       "      <th>unit_of_measurement</th>\n",
       "      <th>altitude_low_meters</th>\n",
       "      <th>altitude_high_meters</th>\n",
       "      <th>altitude_mean_meters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>1950-2200</td>\n",
       "      <td>guji-hambela</td>\n",
       "      <td>300</td>\n",
       "      <td>60 kg</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td>90.58</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Green</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2075.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>1950-2200</td>\n",
       "      <td>guji-hambela</td>\n",
       "      <td>300</td>\n",
       "      <td>60 kg</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td>89.92</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Green</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2075.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>grounds for health admin</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>san marcos barrancas \"san cristobal cuch</td>\n",
       "      <td>1600 - 1800 m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>89.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>yidnekachew dabessa</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>yidnekachew dabessa coffee plantation</td>\n",
       "      <td>1800-2200</td>\n",
       "      <td>oromia</td>\n",
       "      <td>320</td>\n",
       "      <td>60 kg</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td>89.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Green</td>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Arabica</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>metad plc</td>\n",
       "      <td>1950-2200</td>\n",
       "      <td>guji-hambela</td>\n",
       "      <td>300</td>\n",
       "      <td>60 kg</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td>88.83</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Green</td>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2075.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Species                     Owner Country_of_Origin  \\\n",
       "0           0  Arabica                 metad plc          Ethiopia   \n",
       "1           1  Arabica                 metad plc          Ethiopia   \n",
       "2           2  Arabica  grounds for health admin         Guatemala   \n",
       "3           3  Arabica       yidnekachew dabessa          Ethiopia   \n",
       "4           4  Arabica                 metad plc          Ethiopia   \n",
       "\n",
       "                                  Farm.Name       Altitude        Region  \\\n",
       "0                                 metad plc      1950-2200  guji-hambela   \n",
       "1                                 metad plc      1950-2200  guji-hambela   \n",
       "2  san marcos barrancas \"san cristobal cuch  1600 - 1800 m           NaN   \n",
       "3     yidnekachew dabessa coffee plantation      1800-2200        oromia   \n",
       "4                                 metad plc      1950-2200  guji-hambela   \n",
       "\n",
       "   Number.of.Bags Bag.Weight Harvest.Year  ... CoffeeScore Moisture  \\\n",
       "0             300      60 kg         2014  ...       90.58     0.12   \n",
       "1             300      60 kg         2014  ...       89.92     0.12   \n",
       "2               5          1          NaN  ...       89.75     0.00   \n",
       "3             320      60 kg         2014  ...       89.00     0.11   \n",
       "4             300      60 kg         2014  ...       88.83     0.12   \n",
       "\n",
       "  Category.One.Defects  Quakers  Color  Category.Two.Defects  \\\n",
       "0                    0      0.0  Green                     0   \n",
       "1                    0      0.0  Green                     1   \n",
       "2                    0      0.0    NaN                     0   \n",
       "3                    0      0.0  Green                     2   \n",
       "4                    0      0.0  Green                     2   \n",
       "\n",
       "   unit_of_measurement  altitude_low_meters  altitude_high_meters  \\\n",
       "0                    m               1950.0                2200.0   \n",
       "1                    m               1950.0                2200.0   \n",
       "2                    m               1600.0                1800.0   \n",
       "3                    m               1800.0                2200.0   \n",
       "4                    m               1950.0                2200.0   \n",
       "\n",
       "   altitude_mean_meters  \n",
       "0                2075.0  \n",
       "1                2075.0  \n",
       "2                1700.0  \n",
       "3                2000.0  \n",
       "4                2075.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete unnecessary columnS\n",
    "del coffee_df_new['Lot.Number']\n",
    "del coffee_df_new['Mill']\n",
    "del coffee_df_new['ICO.Number']\n",
    "del coffee_df_new['Company']\n",
    "del coffee_df_new['Producer']\n",
    "del coffee_df_new['In.Country.Partner']\n",
    "del coffee_df_new['Certification.Body']\n",
    "del coffee_df_new['Certification.Address']\n",
    "del coffee_df_new['Certification.Contact']\n",
    "del coffee_df_new['Owner.1']\n",
    "del coffee_df_new['Expiration']\n",
    "\n",
    "coffee_df_new.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f2e43dd8-f475-43bb-9952-1f9f1973fc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1339 entries, 0 to 1338\n",
      "Data columns (total 33 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Unnamed: 0            1339 non-null   int64  \n",
      " 1   Species               1339 non-null   object \n",
      " 2   Owner                 1332 non-null   object \n",
      " 3   Country_of_Origin     1338 non-null   object \n",
      " 4   Farm.Name             980 non-null    object \n",
      " 5   Altitude              1113 non-null   object \n",
      " 6   Region                1280 non-null   object \n",
      " 7   Number.of.Bags        1339 non-null   int64  \n",
      " 8   Bag.Weight            1339 non-null   object \n",
      " 9   Harvest.Year          1292 non-null   object \n",
      " 10  Grading.Date          1339 non-null   object \n",
      " 11  Variety               1113 non-null   object \n",
      " 12  Processing_Method     1169 non-null   object \n",
      " 13  Aroma                 1339 non-null   float64\n",
      " 14  Flavor                1339 non-null   float64\n",
      " 15  Aftertaste            1339 non-null   float64\n",
      " 16  Acidity               1339 non-null   float64\n",
      " 17  Body                  1339 non-null   float64\n",
      " 18  Balance               1339 non-null   float64\n",
      " 19  Uniformity            1339 non-null   float64\n",
      " 20  Clean.Cup             1339 non-null   float64\n",
      " 21  Sweetness             1339 non-null   float64\n",
      " 22  Cupper.Points         1339 non-null   float64\n",
      " 23  CoffeeScore           1339 non-null   float64\n",
      " 24  Moisture              1339 non-null   float64\n",
      " 25  Category.One.Defects  1339 non-null   int64  \n",
      " 26  Quakers               1338 non-null   float64\n",
      " 27  Color                 1121 non-null   object \n",
      " 28  Category.Two.Defects  1339 non-null   int64  \n",
      " 29  unit_of_measurement   1339 non-null   object \n",
      " 30  altitude_low_meters   1109 non-null   float64\n",
      " 31  altitude_high_meters  1109 non-null   float64\n",
      " 32  altitude_mean_meters  1109 non-null   float64\n",
      "dtypes: float64(16), int64(4), object(13)\n",
      "memory usage: 345.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Clean Country of Origin\n",
    "coffee_df_new['Country_of_Origin'] = coffee_df_new['Country_of_Origin'].replace(['United States (Hawaii)'],\n",
    "                                                                                'United States (HI)').replace(['United States (Puerto Rico)'],\n",
    "                                                                                                              'United States (PR)').replace(['Tanzania, United Republic Of'], 'Tanzania')\n",
    "\n",
    "# Clean Region\n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['campos altos - cerrado',\n",
    "                                                           'carmo de minas', 'high mogiana',\n",
    "                                                           'mantiqueira de minas', 'minas gerais, br',\n",
    "                                                           'mogiana', 'monte carmelo', 'mountains of minas gerais'],\n",
    "                                                          'Minas Gerais').replace(['south of minas', 'sul de minas',\n",
    "                                                                                   'sul de minas - carmo de minas'],\n",
    "                                                                                  'Sul de Minas').replace(['alta paulista (sao paulo)'],\n",
    "                                                                                                          'Alta Paulista').replace(['brazil matas de minas'],\n",
    "                                                                                                                                   'matas de minas').replace(['cerrado - monte carmelo - minas gerais',\n",
    "                                                                                                                                   'chapadÃ£o de ferro (cerrado mineiro)'],\n",
    "                                                                                                                                   'cerrado').replace(['vale da grama'], 'grama valley')\n",
    "\n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['52 narino (exact location: mattituy; municipal region: florida code 381',\n",
    "                                                           'nariÃ±o'], 'Narino').replace(['huila supremo', 'south huila'], 'huila')\n",
    "\n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['valle central'], 'central valley').replace(['west and central valley'], 'west valley')\n",
    "\n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['ataco, apaneca - ilamatepec mountain range',\n",
    "                                                           'department of ahuachapan, municipality of apanecallamatepec mountain'],\n",
    "                                                           'apaneca').replace(['el balsamo, quezaltepec'], 'Chalatenango')\n",
    "                                                           \n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['province of manabi, ecuador'], 'Manabi').replace(['san juan, playas'], 'San Juan')\n",
    "                                                           \n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['blida,kercha,guji,oromia',\n",
    "                                                           'guji-hambela'], 'Guji').replace(['kefa zone, gimbo distict, at a place called woka araba, south west ethiopia.'],\n",
    "                                                                                            'Keffa Zone').replace(['gedio',\n",
    "                                                                                                                   'snnp/kaffa zone,gimbowereda',\n",
    "                                                                                                                   'snnprg; kafa; telo woreda; shada kebele'], 'SNNPR').replace(['ethiopia, sidamo',\n",
    "                                                                                                                   'sidamo'], 'Sidama').replace(['kelem welega', 'limu', 'oromiya'],\n",
    "                                                                                                                                                'oromia').replace(['aricha'], 'yirgacheffe')\n",
    "\n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['chuva, san marcos', \n",
    "                                                           'el tumbador, san marcos',\n",
    "                                                           'la reforma, san marcos'],\n",
    "                                                          'san marcos').replace(['nuevo oriente', 'orient', 'oriente'],\n",
    "                                                                                 'santa rosa').replace(['san lucas toliman, solola'],\n",
    "                                                                                                       'solola').replace(['aldea xeucalvitz, ixil region, quiche department'],\n",
    "                                                                                                                         'Quiche').replace(['sacatepequez, guatemala'],\n",
    "                                                                                                                                           'Sacatepequez')\n",
    "\n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace([\"department d'artibonite , haiti\"],\n",
    "                                                           'Artibonite').replace(['dondon, haiti'],\n",
    "                                                                                 'Dondon').replace(['thiotte, haiti'], 'Thiotte')\n",
    "                                                           \n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['central region',\n",
    "                                                           'comayagua, honduras', 'siguatepeque, comayagua'],\n",
    "                                                          'comayagua').replace(['el paraÃso',\n",
    "                                                                                'guinope el paraÃso'], 'El Paraiso').replace(['marcala'],\n",
    "                                                                                                                              'La Paz').replace(['san marcos'], 'ocotepeque')\n",
    "                                                           \n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['chickmangalore', 'chikmagalur karnataka',\n",
    "                                                           'chikmagalur karnataka india', 'chikmagalur karnataka indua'],\n",
    "                                                          'chikmagalur') \n",
    "                                                           \n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['aceh gayo',\n",
    "                                                           'aceh tengah'], 'aceh').replace(['lington nihuta',\n",
    "                                                                                            'lintong', 'sumatra brastagi'],\n",
    "                                                                                           'Sumatra').replace(['central kenya'],\n",
    "                                                                                                              'Central').replace(['temanggung, indonesia'],\n",
    "                                                                                                                                 'Central Java')\n",
    "                                                           \n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['lao p.d.r.'],\n",
    "                                                          'Bolaven Plateau').replace(['paksong,laos'],\n",
    "                                                                                     'Paksong').replace(['chamarel (south west)'],\n",
    "                                                                                                        'Chamarel')\n",
    "                                                           \n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['los angeles'],\n",
    "                                                          'Baja').replace(['amatenango de la frontera',\n",
    "                                                                           'chiapas, jaltenango', 'chilÃ³n',\n",
    "                                                                           'escuitla', 'jaltenango', 'la concordia',\n",
    "                                                                           'la concordia, chiapas', 'motozintla',\n",
    "                                                                           'motozintla, chiapas', 'ocosingo',\n",
    "                                                                           'sacÃºn palma, municipio de chilÃ³n, chiapas',\n",
    "                                                                           'san pedro cotzilnam', 'santa maria sitepec',\n",
    "                                                                           'sierra fraylesca, chiapas', 'sierra norte yajalon, chiapas',\n",
    "                                                                           'sierra, chiapas', 'siltepec el triunfo',\n",
    "                                                                           'siltepec el triunfo, chiapas, mexico', 'tapachula',\n",
    "                                                                           'tuxtla gutierrez', 'yajalon'],\n",
    "                                                                          'chiapas').replace(['canoas', 'cofradia de suchitlan',\n",
    "                                                                                              'el remudadero', 'la cumbre', 'manzanillo'], 'colima').replace(['cuarenteÃ±o'],\n",
    "                                                                                              'El Cuarenteno').replace(['atoyac de alvarez', 'iliatenco, guerrero',\n",
    "                                                                                                                        'zihuatanejo de azueta'],\n",
    "                                                                                                                       'Guerrero').replace(['calnali, hidalgo',\n",
    "                                                                                                                                            'chapulhuacan, hidalgo',\n",
    "                                                                                                                                            'huazalingo, hidalgo', 'jaltocan, hidalgo',\n",
    "                                                                                                                                            'san bartolo tutotepec', 'tenango de doria, hidalgo',\n",
    "                                                                                                                                            'tlanchinol, hidalgo'], 'Hidalgo') \n",
    "                                                           \n",
    "                                                           \n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['el desmoronado, talpan de allende jalisco',\n",
    "                                                           'talpa de allende'], 'Jalisco').replace(['santo reyes nopala'],\n",
    "                                                                                                   'juquila').replace(['adolfo lopez mateos',\n",
    "                                                                                                                       'tepetzingo'], 'mexico').replace(['ohuapan, tlaltetela'],\n",
    "                                                                                                                       'Michoacan').replace(['la yerba', 'la yerbabuena'],\n",
    "                                                                                                                                            'nayarit')\n",
    "                                                           \n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['huautla de jimenez', 'pluma hidalogo, oaxaca',\n",
    "                                                           'san miguel del puerto', 'santa catarina juquila',\n",
    "                                                           'santo domingo cacalotepec', 'sierra alta mixe y zapoteca',\n",
    "                                                           'temaxcalapa', 'villa talea de castro', 'xochitonalco, huautla',\n",
    "                                                           'zaragoza itundujia'], 'oaxaca').replace(['tlacuilotepec', 'tlatlauquitepec',\n",
    "                                                                                                     'xicotepec de juarez',\n",
    "                                                                                                     'zapotitlan de mendez'], 'Puebla').replace(['san fernando'], 'Tamaulipas')  \n",
    "                                                           \n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['altotonga', 'chocaman, veracruz', 'coatepec', 'coatepec, coatepec',\n",
    "                                                           'coscomatepec', 'fortÃn de las flores', 'hustusco', 'ixhuatlan del cafe',\n",
    "                                                           'juchique de ferrer', 'mahuixtlan', 'progreso santa rosa teocelo', 'tepictla',\n",
    "                                                           'totutla', 'xalapa', 'yecuatla', 'zentla'], 'Veracruz')\n",
    "                                                           \n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['doe kwin, pyin oo lwin', 'pyin oo lwin'],\n",
    "                                                          'pyinoolwin').replace(['yauk sauk, shan state'],\n",
    "                                                                                'South Shan State').replace(['ywar ngan township'],\n",
    "                                                                                                            'ywar ngan').replace(['dipilto, nueva segovia'],\n",
    "                                                                                                                                 'nueva segovia')\n",
    "                                                           \n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['chiayi alishan å˜‰ç¾©ç¸£é˜¿é‡Œå±±é„‰',\n",
    "                                                           'chiayi fanluå˜‰ç¾©ç¸£ç•ªè·¯é„‰',\n",
    "                                                           'leye, alishan township, chiayi county',\n",
    "                                                           'leye, alishan township, chiayi county å˜‰ç¾©é˜¿é‡Œå±±æ¨‚é‡Žæ‘'],\n",
    "                                                          'Chiayi').replace(['changhua baguashan å½°åŒ–å¸‚å…«å¦å±±'],\n",
    "                                                                            'Changhua').replace(['yunlin é›²æž—ç¸£çŸ³å£',\n",
    "                                                                                                 'yunlin gukeng he bao é›²æž—ç¸£å¤å‘é„‰è·è‹žæ‘'],\n",
    "                                                                                                'Gukeng Township').replace(['åœ‹å§“é„‰ guoshing township'],\\\n",
    "                                                                                                                           'Guoshing Township').replace(['natou county'],\n",
    "                                                                                                                           'nantou')\n",
    "                                                           \n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['taichung taiping å°ä¸å¸‚å¤ªå¹³å€',\n",
    "                                                           'taichung xinshe å°ä¸­å¸‚æ–°ç¤¾å€'],\n",
    "                                                          'Taichung').replace(['å°å—å¸‚æ±å±±å€ (dongshan dist., tainan city)',\n",
    "                                                                               'å°å—å¸‚æ±å±±å€( dongshan dist., tainan city)',\n",
    "                                                                               'baihe dist., tainan city è‡ºå—å¸‚ç™½æ²³å€',\n",
    "                                                                               'dongshan dist., tainan city å°å—å¸‚æ±å±±å€',\n",
    "                                                                               'dongshan dist., tainan city è‡ºå—å¸‚æ±å±±å€',\n",
    "                                                                               'nanxi dist., tainan city è‡ºå—å¸‚æ¥ è¥¿å€'],\n",
    "                                                                              'Tainan City').replace(['å˜‰ç¾©é˜¿é‡Œå±±', 'å¤å‘é„‰è·åŒ…æ‘å°–å±±å‘60è™Ÿ',\n",
    "                                                                                                      'å°ä¸­å’Œå¹³å€', 'å°ä¸­æ–°ç¤¾', 'å°æ±å¤ªéº»é‡Œ', 'å°ç£',\n",
    "                                                                                                      'å—æŠ•åœ‹å§“', 'è‹—æ —ä¸‰ç£', 'è‹—æ —æ³°å®‰',\n",
    "                                                                                                      'taiwu township , pingtung county å±æ±ç¸£æ³°æ­¦é„‰'], 'Taiwu Township')\n",
    "                                                           \n",
    "                                                           \n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['arusha meru'], 'arusha').replace(['luwero central region'],\n",
    "                                                                                             'central').replace(['chiang rai thailand',\n",
    "                                                                                                                 'chiangrai', 'doi chaang village, chiang rai, thialand',\n",
    "                                                                                                                 'thailand'], 'chiang rai').replace(['bulambuli eastern region',\n",
    "                                                                                                                                                     'eastern uganda',\n",
    "                                                                                                                                                     'iganga namadrope eastern'],\n",
    "                                                                                                                                                    'eastern').replace(['kapchorwa eastern'], 'kapchorwa')\n",
    "                                                           \n",
    "coffee_df_new['Region'] = coffee_df_new['Region'].replace(['karatu arusha',\n",
    "                                                           'karatu ngorogoro', 'karatu northern',\n",
    "                                                           'manyara, karatu'], 'Karatu').replace(['kasese, mt. rwenzori'],\n",
    "                                                                                                 'kasese').replace(['iwala village, mbeya rural'],\n",
    "                                                                                                                   'mbeya').replace(['sipi, mt elgon'],\n",
    "                                                                                                                                    'mt elgon').replace(['ruvuma, mbinga'],\n",
    "                                                                                                                                    'ruvuma').replace(['sheema south western'],\n",
    "                                                                                                                                                      'south western')\n",
    "                                                           \n",
    "coffee_df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "969d900e-96ca-414c-a7f0-7be2163681f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows with United States as country due to invalid Region\n",
    "coffee_df_new = coffee_df_new[coffee_df_new[\"Country_of_Origin\"] != \"United States\"]\n",
    "\n",
    "# Delete all rows with blank values in BOTH processing method and altitude\n",
    "coffee_df_new = coffee_df_new.dropna(subset=[\"Processing_Method\", \"Altitude\"], how=\"all\")\n",
    "\n",
    "# Delete [4] rows with anomalous values in place of data\n",
    "coffee_df_new = coffee_df_new[coffee_df_new[\"Altitude\"] != \"mmm\"]\n",
    "coffee_df_new = coffee_df_new[coffee_df_new[\"Altitude\"] != \"test\"]\n",
    "coffee_df_new = coffee_df_new[coffee_df_new[\"Altitude\"] != \"huanuco\"]\n",
    "coffee_df_new = coffee_df_new[coffee_df_new[\"Altitude\"] != \"-1\"]\n",
    "\n",
    "coffee_df_new.to_csv(\"Coffee_exp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed962d1-e20f-403f-838a-d2b0ef244b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SNEHA -- START -- BUCKET METRICS (HIGH, MEDIUM, LOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8626235-faa1-4351-9371-5a24ef2573c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creatimng High/Average/Low values for each coffee metric score\n",
    "def Score_categories(DataFrame, Score_Columns): \n",
    "    for i, m in enumerate(Score_Columns):\n",
    "        percentiles =DataFrame[{m}].quantile([(1/3),(2/3)])\n",
    "\n",
    "        conditions = [(DataFrame[{m}] <= (1/3)),(DataFrame[{m}] > (1/3)) & (DataFrame[{m}] <= (2/3)),(DataFrame[{m}] > (2/3))]\n",
    "        values = ['High', 'Average', 'Low']\n",
    "        DataFrame[f\"{m}_cat\"] = np.select(conditions, values)\n",
    "\n",
    "metrics = ['Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body',\n",
    "'Balance', 'Uniformity', 'Clean.Cup', 'Sweetness', 'Cupper.Points',\n",
    "'CoffeeScore', 'Moisture', 'Category.One.Defects', 'Quakers', 'Category.Two.Defects','altitude_mean_meters','Number.of.Bags']\n",
    "Score_categories(coffee_df_new, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1465ae-fbfb-4954-b4a6-92dca65667e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3de9ea-7b36-473a-8eab-de91b0344281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SNEHA -- END -- BUCKET METRICS (HIGH, MEDIUM, LOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e934054b-7da7-4d8a-9a4e-8a8872093938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAYLOR -- START -- GENERAL EDA -- STATISTICS by SPECIES (Can we condense to a function?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ef27d-7c14-4417-9503-5b8abe2017eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at key metrics by species\n",
    "#Coffee Score by Species\n",
    "species_group = coffee_df_new.groupby('Species')\n",
    "coffee_score_species_metrics = species_group.agg({\"CoffeeScore\": [\"mean\", \"median\", \"var\", \"std\", \"sem\"]})\n",
    "coffee_score_species_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4b5f8c-a47c-488d-993d-c7137a1ad5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given the high ariance in coffee scores, in particular among arabica variaties, we can use a box plot to show distribution of coffee scores\n",
    "\n",
    "#Calculate upper and lower bounds, IQR and identify outliers\n",
    "\n",
    "#Create boxplot\n",
    "# plt.boxplot(coffee_df_new)\n",
    "# plt.xticks([1, 2], ['Arabica', 'Robusta']) \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91029d96-01f5-424c-98ca-f3fdfb5f91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flavor by Species\n",
    "flavor_species_metrics = species_group.agg({\"Flavor\": [\"mean\", \"median\", \"var\", \"std\", \"sem\"]})\n",
    "flavor_species_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd29051-43b3-473c-89a0-0bff48e8b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aroma by Species\n",
    "aroma_species_metrics = species_group.agg({\"Aroma\": [\"mean\", \"median\", \"var\", \"std\", \"sem\"]})\n",
    "aroma_species_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024c8ab2-3bd3-4c1a-ac08-b5117134897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aftertaste by Species\n",
    "aftertaste_species_metrics = species_group.agg({\"Aftertaste\": [\"mean\", \"median\", \"var\", \"std\", \"sem\"]})\n",
    "aftertaste_species_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace99ad-d045-4b44-b6dc-1567edf3c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at key metrics by processing method\n",
    "processing_method_group = coffee_df_new.groupby('Processing_Method')\n",
    "coffee_score_pm_metrics = processing_method_group.agg({'CoffeeScore': [\"mean\", \"median\", \"var\", \"std\", \"sem\"]})\n",
    "coffee_score_pm_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd8f636-d665-4cb4-b4e4-3f4708120bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a bar graph of coffee scores by processing method\n",
    "# plt.bar(processing_method_group['Processing_Method'], processing_method_group['CoffeeScore'])\n",
    "# plt.xlabel(\"Processing_Method\")\n",
    "# plt.ylabel(\"CoffeeScore\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410918c1-8e86-4e85-b35c-1675552cac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GroupBy Species and Country of Origin\n",
    "#Count coffees by country for each species\n",
    "species_by_country = coffee_df_new.groupby(['Species'])['Country_of_Origin'].value_counts()\n",
    "species_by_country\n",
    "\n",
    "#Look at percentage of coffees by country\n",
    "#count_of_species = coffee_df_new['Species'].value_counts()\n",
    "#count_of_species\n",
    "#species_percent_by_country = species_by_country / count_of_species \n",
    "#species_percent_by_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcfd638-f702-4a93-9bca-b3ac6cd5f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAYLOR -- END -- GENERAL EDA -- STATISTICS by SPECIES (Can we condense to a function?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3d9553-6f7e-4f19-8e45-f2480ff6f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SNEHA -- START -- BOXPLOTS by SPECIES/ANY FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be242f-b010-4db4-9180-71512c9518ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put treatments into a list for for loop (and later for plot labels)\n",
    "# Create empty list to fill with tumor vol data (for plotting)\n",
    "species = [\"Arabica\", \"Robusta\"]\n",
    "metrics = ['Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body',\n",
    "       'Balance', 'Uniformity', 'Clean.Cup', 'Sweetness', 'Cupper.Points',\n",
    "       'Total.Cup.Points', 'Moisture', 'Category.One.Defects', 'Quakers', 'Category.Two.Defects','altitude_mean_meters','Number.of.Bags']\n",
    "metric_value = []\n",
    "\n",
    "# Calculate the IQR and quantitatively determine if there are any potential outliers. \n",
    "    # Locate the rows which contain mice on each drug and get the tumor volumes\n",
    "    # add subset \n",
    "    # Determine outliers using upper and lower bounds\n",
    "for j,m in enumerate(metrics):\n",
    "    for i,sp in enumerate(species):\n",
    "        metric_value.append(coffee_df.loc[(coffee_df[\"Species\"]==sp),f\"{m}\"])\n",
    "        percentiles = metric_value[i].quantile([0.25,0.5,0.75])\n",
    "        upperq = percentiles[0.75]\n",
    "        lowerq = percentiles[0.25]\n",
    "        IQR = upperq-lowerq\n",
    "        upper_lim = upperq+(1.5*IQR)\n",
    "        lower_lim = lowerq-(1.5*IQR)\n",
    "        outliers = [tv for tv in metric_value[i] if (tv<lower_lim) | (tv>upper_lim)]\n",
    "        print(f\"{(sp)}'s {m}:\\nPotential outliers are :{outliers} \\nInterquartile Range is :{round(IQR,2)}\\n\\n \")\n",
    "        \n",
    "    plt.boxplot(metric_value,0,flierprops={'marker': '.', 'markersize': 6, 'markerfacecolor': 'r','markeredgecolor':'k','linewidth':'1'})\n",
    "\n",
    "    font = {'color':  'blue','fontweight': '3','fontsize': 14}    \n",
    "    plt.title(f\"{m} Distribution\",fontdict=font)       \n",
    "\n",
    "    plt.ylabel(f\"{m}\")\n",
    "    plt.xticks([int(i+1) for i in range(len(species))],labels = species)\n",
    "    plt.savefig(f\"data/Boxplots/{m}.png\")\n",
    "    metric_value=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758fa1de-6757-4b16-ae31-34e5fe36e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SNEHA -- END -- GENERAL EDA -- BOXPLOTS by SPECIES/ANY FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956c75af-a913-4e53-9c8d-000e6f2af9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SNEHA -- START -- GENERAL EDA -- REGRESSION by SPECIES/ANY FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad627e90-7a94-4ee3-99c5-025f83d0397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create Linear Regression plots\n",
    "def plot_scatters(Dataframe,X_Column_List,Y_Column_List,Categories):\n",
    "\n",
    "    for j,X_Column in enumerate(X_Column_List): \n",
    "        \n",
    "        for i,Y_Column in enumerate(Y_Column_List):\n",
    "\n",
    "            for h,hem in enumerate(Categories):\n",
    "                        \n",
    "                        if X_Column== Y_Column:\n",
    "                            continue\n",
    "\n",
    "                        plot_df =  Dataframe.loc[Dataframe[\"Species\"]== hem,[X_Column,Y_Column]].reset_index(drop=True)\n",
    "                        plot_df.plot(kind=\"scatter\",x=X_Column,y=Y_Column,s=40,marker =\"o\",color=\"blue\",edgecolor =\"k\",grid=True, figsize=(8,6),\\\n",
    "                        xlabel = f\"{X_Column}\", ylabel = f\"{Y_Column}\") \n",
    "                        font = {'color':  'blue','fontweight': '3','fontsize': 14}    \n",
    "\n",
    "\n",
    "                        plt.title(f\"{hem}: {X_Column} Vs. {Y_Column}\",fontdict=font)  \n",
    "\n",
    "                        xaxis = plot_df[X_Column]\n",
    "                        yaxis =  plot_df[Y_Column]\n",
    "\n",
    "                        xmin = xaxis.min()- 0.1 * (xaxis.max()-xaxis.min())\n",
    "                        xmax= xaxis.max()+ 0.1 * (xaxis.max()-xaxis.min())\n",
    "                        ymin=yaxis.min()- 0.1 * (yaxis.max()-yaxis.min())\n",
    "                        ymax=yaxis.max()+ 0.1 * (yaxis.max()-yaxis.min())\n",
    "                        plt.xlim(xmin,xmax)\n",
    "                        plt.ylim(ymin,ymax)\n",
    "\n",
    "                        (slope, intercept, r, p, std_e) = stats.linregress(xaxis,yaxis)\n",
    "                        regress_line = (slope * xaxis) + intercept\n",
    "                        regress_eq = \"Y = \" + str(round(slope,2))+ \"* X + \" + str(round(intercept,2))\n",
    "\n",
    "                        plt.plot(xaxis,regress_line,color = \"r\")\n",
    "                        plt.annotate(regress_eq,xy=(xmin+((xmax - xmin)/2),yaxis.min()- 0.08 * (yaxis.max()-yaxis.min())),color=\"r\",fontsize=14)\n",
    "                        plt.annotate(f\"The R-Squared Value is: {round(r,2)}\",xy=(xmin,yaxis.min()- 0.08 * (yaxis.max()-yaxis.min())),color=\"r\",fontsize=14)\n",
    "                        plt.tight_layout()\n",
    "                        \n",
    "                        plt.savefig(f\"data/Regression/{hem}:{X_Column}-{Y_Column}.png\")\n",
    "\n",
    "                \n",
    "species = [\"Arabica\", \"Robusta\"]\n",
    "y_col_list = ['Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body','Balance', 'Uniformity', 'Clean.Cup', 'Sweetness','Moisture'\\\n",
    "              , 'Category.One.Defects',  'Category.Two.Defects','altitude_mean_meters','Number.of.Bags']\n",
    "x_col_list = ['Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body','Balance', 'Uniformity', 'Clean.Cup', 'Sweetness', 'Moisture'\\\n",
    "              , 'Category.One.Defects', 'Category.Two.Defects','altitude_mean_meters','Number.of.Bags']\n",
    "\n",
    "plot_scatters(coffee_df,x_col_list,y_col_list,species)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600ccc6-9f3d-4cf5-91db-24e565127290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SNEHA -- END -- GENERAL EDA -- REGRESSION by SPECIES/ANY FUNCTION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
